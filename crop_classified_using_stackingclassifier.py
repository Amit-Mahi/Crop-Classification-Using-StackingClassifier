# -*- coding: utf-8 -*-
"""crop classified using StackingClassifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AVsRC26P6YCxEilcRYGXkFEq6yQ3coE5
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder, label_binarize
from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier

df = pd.read_csv("/content/Crop_recommendation.csv")
df.head()

# Encode target labels
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(df['label'])

# Features
X = df.drop('label', axis=1)

# Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Scale
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Binarize labels for ROC AUC
y_test_bin = label_binarize(y_test, classes=np.unique(y))

"""# Base Learner and Meta Learner  ( EXECUTION EXPLAINATION )

## Base learner -
    SVM, LR, KNN, CART (Decision Tree) these algorithm out a number of probabilities (depending on how many crops are there). For Example - if there are 10 crops the output would be [0.2,0.1,0.5,.....,0.2].

    Then Four base Models will create 10 X 4 = 40 matrix dataset for the Meta Leaner.
  
## Meta Learner -
    Trained on the Matrix dataset produced by the base learner Models it will give the Final Prediction on the Crop Classification.
"""

base_learners = [
    ('svm', SVC(probability=True, random_state=42)),
    ('knn', KNeighborsClassifier(n_neighbors=5)),
    ('nb', GaussianNB()),
    ('cart', DecisionTreeClassifier(random_state=42))
]

# Define meta learner (level-1 classifier)
meta_learner = LogisticRegression(max_iter=2000, random_state=42)

# Create stacking classifier
stacking_clf = StackingClassifier(
    estimators=base_learners,
    final_estimator=meta_learner,
    cv=5,
    stack_method='predict_proba',
    n_jobs=-1
)

stacking_clf.fit(X_train_scaled, y_train)

# Predictions
y_pred = stacking_clf.predict(X_test_scaled)
y_proba = stacking_clf.predict_proba(X_test_scaled)

# Metrics
accuracy = accuracy_score(y_test, y_pred) * 100
conf_matrix = confusion_matrix(y_test, y_pred)
roc_auc = roc_auc_score(y_test_bin, y_proba, multi_class='ovr')

print(f"Stacking Classifier Results:\n")
print(f"‚úÖ Accuracy: {accuracy:.2f}%")
print(f"‚úÖ ROC AUC: {roc_auc:.4f}")

from sklearn.model_selection import GridSearchCV

base_learners = [
    ('svm', SVC(probability=True)),
    ('lr', LogisticRegression(max_iter=500)),
    ('knn', KNeighborsClassifier()),
    ('cart', DecisionTreeClassifier())
]

# Meta learner
meta_learner = RandomForestClassifier(random_state=42)

# Stacking Classifier
stack_model = StackingClassifier(
    estimators=base_learners,
    final_estimator=meta_learner,
    passthrough=False
)

# Define parameter grid for tuning
param_grid = {
    'svm__C': [0.1, 1, 10],
    'svm__kernel': ['linear', 'rbf'],
    'knn__n_neighbors': [3, 5, 7],
    'cart__max_depth': [None, 5, 10],
    'final_estimator__n_estimators': [100, 200],
    'final_estimator__max_depth': [None, 10, 20]
}

# Grid Search with 5-fold CV
grid = GridSearchCV(
    estimator=stack_model,
    param_grid=param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=2
)

# Fit to data
grid.fit(X_train, y_train)

print("Best Parameters:", grid.best_params_)
print("Best CV Score:", grid.best_score_)

# Evaluate on test set
best_model = grid.best_estimator_
test_acc = best_model.score(X_test, y_test)
print("Test Accuracy:", test_acc)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=False, cmap="Blues")
plt.title("Confusion Matrix - Stacking Classifier")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

def predict_crop_stacking(model, scaler, label_encoder):
    print("Enter the following details:")

    try:
        N = float(input("Nitrogen (N): "))
        P = float(input("Phosphorous (P): "))
        K = float(input("Potassium (K): "))
        rainfall = float(input("Rainfall (mm): "))
        temperature = float(input("Temperature (¬∞C): "))
        humidity = float(input("Humidity (%): "))
        ph = float(input("pH value: "))
    except ValueError:
        print("‚ùå Invalid input. Please enter numeric values.")
        return

    # Prepare input
    input_features = np.array([[N, P, K, rainfall, temperature, humidity, ph]])
    input_scaled = scaler.transform(input_features)

    # Predict
    pred_encoded = model.predict(input_scaled)[0]
    pred_label = label_encoder.inverse_transform([pred_encoded])[0]

    print(f"\nüå± Recommended Crop: **{pred_label.upper()}**")

predict_crop_stacking(stacking_clf, scaler, label_encoder)





